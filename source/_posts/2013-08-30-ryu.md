---
layout: post
title: 'Ryu'
date: 2013-08-30 06:19
comments: true
categories: 
---
Figure 1 (要有原本的tree)
Figure 2 (後來的tree)



abstract.

introduction.
介紹SDN
http://www.opendaylight.org/project/technical-overview
SDN enables users to program network layers, separating the data plan from the control plane. By enabling programmability, SDN can enable users to optimize their network resources, increase network agility, service innovation, accelerate service time-to-market, extract business intelligence and ultimately enable dynamic, service-driven virtual networks. 


//
Software-Defined Networks (SDN) is a emerging network archtechure.這種架構將控制與資料分開來，是個可編寫，中央控制，動態，有彈性的網路架構。他的目的在於提供更高的網路效能，網路資料更好操作，管理，更低成本。
在ＳＤＮ之中，所有網路的計算都交由ＣＯＮＴＲＯＬＬＥＲ來完成，ＳＷＴＩＣＨ只負責執行相關的ＡＣＴＩＯＮ，然後可以根據特定的需求去撰寫不同功能的硬用。
ＯＰＥＮＦＬＯＷ是一個定義ＳＤＮ中 ＣＯＮＴＲＯＬＬＥＲ跟ＳＷＴＩＣＨ溝通用的協定，由ＯＮＦ推出螑也維護


 
//
驗證
	真實網路
  模擬
//
//
介紹模擬器
//

//
Regarding Openflow controllers,We choose two widely used OpenFlow controller  RYU and NOX  to study in this paper.Both RYU and NOX are real application program written by python and runnable on any operating system supporting python,both them can readily run on any simulated host to controller simulated OpenFlow switches over Estinet with any modificaion.We testd and evaluated those real OpenFlow controller in simulations rather than in eumulations in Estinet,so the tested and evaluated can be performed much faster than real time.Additionally,we can correctly explain the simulated result obtained over Estinet based on the network configuration (e.g., network topology, network size, node mobility pattern or moving speedm etc.) and paramaters setting (e.g., link delay,bandwidth,BER,downtime,packet loss rate, etc.) of the simulated OpenFlow network.
We have used Estinet to perform functional validation and performance evaluation of serveral protocol that are implemented by NOX and RYU as components.In this paper.We choose the learning bridge protocol (LBP) and spanning  tree protocol (STP) as illustration examples.We observ the phenomenon using RYU as OpenFLow controller in network topology with loop and stduied how quickly RYU and NOX can find a new routing path for a greedy TCP flow after a link's status has changed.
We also studied the effect of address resolition protocol (ARP) on the new path finding time over RYU and NOX . Our simulation results and deatiled logs reveal their behavior,efficiency , and implementation flaws under the tested network settings.




Simulation Settings:
我們的模擬使用了圖1的拓樸。
NODE 3 4 5 11 模擬了一個在fedora14上可運行真實世界應用程式的host
switch 6,7,8,9,10 模擬了支援openflow protocol 的openflow switch。
/*
Our simulation use the network topology as shown in figure (1).
node 3,4,5,11 simulate a host running the real world linux operating system (Fedora 14) and  it also can  run a real world linux program without modification.
node 6,7,8,9,10 simulate a openflow switch supporting OpenFlow protocol version 1.0.
*/

node 1是一個運行openflow controller NOX/Ryu的host，
NODE 2是一個傳統的SWTICH,會把所有OPENFLOW SWITCH與CONTROLLER結合再一起。
node2,node1,openflow switch以及他們之間的link定義了control-plane
所有openflow message都會在control-plane上面以TCP連線的方式作交換
host 3,4,5,11 ,openflow switch以及其之間的link定義了data-plane.
所有真實世界應用程式的都會在data-plane上面交換資料。
/*
node 1 is a simulated host running a real world OpenFlow controller,using RYU/NOX in our simulation.
node 2 is a simulated legacy switch connects all the simulated OpenFlow swtich together with the OpenFlow controller.
All established TCP connection between each simulated OpenfFlow switches and the controller node form a control-plane network adn the OpenFlow message between RYU/NOX  and simulated switches will exchange over this control-plane network.
All OpenFlow message between RYU/NOX will exchanged over this control-plane network.
In constrast. all simulated hosts , simulated OpenFlow and all links connecting them together form  the data-plane network over whcih real application running on simulated hosts will exchange their infomation.
*/
我們再圖1有兩個case要模擬
我們令所有case中LINK的bandwidth跟delay都設定程100Mbps,10ms,(data&control-plane)。並且都模擬0~150秒。

case1中
我們只用Ryu作為 OPENFLOW controller,
因為Ryu本身只有使用learngin bridge protocol。	

case2中我們想要測試不同controller需要花多少時間找到新路徑當原有拓樸發生改變時。
每個模擬都總共跑150秒，我們故意讓node9~node10的link在0~60,120~150的時候斷掉，然後再60~120的時候讓node6~node7
在case2中，我們想要研究使用ryu/nox時在link發生問題之後要花多少時間TCP連線能夠繼續。
we want to generate endless TCP traffic from node 3 to node 11.所以我們選擇node 3當作tcp sender,node 10
當作tcp receive.

因為在estinet中可以直接運行真實世界應用程式， 所以我們選擇stcp 跟 rctp 這兩個開源軟體分別代表tcp server  tcp receiver. 我們在node3 上面運行stcp,在node11上面運行rtcp.

我們上這些應用程式的模擬時間從30秒開始，因為在封包盡如data-plane之前我們想要給controller足夠的時間發現整個拓樸並建置spanning tree.
/*

We have two simulation cases on figure 1.
We set the link delay and bandwitdh  to 10 ms and 100 Mbps of each link in control-plane and data-plane in both simulation case 1 and case 2.
Both cases start at 0'th sec and ends at 120'th sec.

Case1:
In case 1,we only use RYU as OpenFlow controller. 
Because RYU only use LBP (Learning Bridge Protocol) to archive packet forwarding,we want to observe the phenomenon of running RYU in a  topology with loop.
Oue simulation result show that there are some phenomenon happen in a topology with loop when RYU is used.

Case2:
In case 2,we want to study the required time to find a new path after a lin's status has changed in both RYU and NOX as OpenFlow controller.
We purposely shut down the link between node 6 and node7 between 40'th sec and 80'th sec and shut down the link between node 9 and node 10 between 0'th sec to  40'th sec  and 80'th sec to 120'th.
We studied how quickly a greedy TCP flow can continue its transfer after a link on its path fails.
we want to gerentae endless TCP traffice from node 3 to node 11, we choose node 3 as TCP sender and node 11 as TCP receiver.
Beacuse in Estinet real application can directly run on simulated hose without modification.
we choose the open source program "stcp" and "rtcp" to act as TCP sender and TCP receiver.
Once the stcp successfully sets up a real TCP connection with rtcp,it generates and sends endless TCP data to the rtcp subject to the TCP error,flow,and congestion control alogrithms.
Both stcp and rtcp are set to start at 30'th sec rather than 0'th sec.This is because we want to give  enough time to OpenFlow controller to discover the topology of the data-plane network and compute the infomation about path finding and packet forwarding before any packet enters into data-plane network.
We also tested the effects of the ARP protocol on the path-finding timefor the TCP flow.Normally,on areal network the ARP protocol is enabled and the host will issues an ARP request to learn (MAC address,IP address) mapping infomation. However, under some circumstances.we will disable the ARP protocol and use the pre-build mapping table to avoid the ARP request/reply latency and bandwidth consumption.
Our simulation result show that there hava a significant impact on path-finding capability and speed for NOX when ARP protocol enable or disable.
/*
--ARP直接照抄就好
改成多一個case2即可。

-------------------------------
PATH-FINDING AND PACKET-FORWARDING FUNCTIONS IN RYU/NOX
這邊介紹ryu跟nox的運作
大綱

Ryu中使用了LBP(Learning Brdige Protocol)來找尋路徑並且傳遞封包。
-----------
當packet到達swtich後，因為在switch中沒有flow entry 可以match,所以會發送packetIn到controller.
當controller收到packetIn時，會先學習此封包，建立一個{switchDipd,mac} = switchPort的對應表，接者
會先查詢是否知道destination mac address 要從哪個port出去，如果知道就會送一個對應的flow modify 給switch告訴它當match到dest mac時就從某個ＰＯＲＴ出去，如果不知道destination 的話，就送一個帶有ＦＬＯＯＤ ＡＣＴＩＯＮ的ＰＡＣＫＥＴＯＵＴ給switch。
-------------

這邊我們使用圖1來解釋其原理。

為了能夠更清楚的解釋其原理.
我們假設圖一中的NODE9~NODE10的link 當掉forever來形成一個loopless的網路。

/*
Ryu use LBP (Learning Brdige Protocol) to fulfill path finding and packet forwarding.
When a switch issue PacketIn message to Ryu, Ryu will learn a {switch dpid,source host's mac} = switchPort mapping infomation.If Ryu hava infomation for the destination host,it will send a FlowModify message to switch to add a new flow entry and a PacketOut message to switch to output packet to specific port.Otherwise it will send  a PacketOut message to switch to flood packet.
Here we use figure 1 to explain how it works on thie network.
To present how it works more clearly , we assume the link connecting node 9 to node 10 is down.
*/

我們假設host 3 以TCP的方式送第一個data到host 11。
當data到達swtich 6的時候，因為在flow-table中找不到可以match 的entry,所以table miss event，swtich 6會發送Packet_In message給controller,controller會學習到{swtich6,node3's mac} = switch6's port 1 這個對照表，然後
因為controller並沒有任何host11的資訊，所以會回送一個Packet_Out告訴swtich6把風包給flood出去。當swtich 6收到Packet_out後，就會把封包給flood出去。
/*
Suppose the source node 3 send a TCP DATA packet to destination node 11.
When packet arrived node 6,because there is no flow entry in the flow table that can match it,switch send a PacketIn message to Ryu asking it how to process this packet.After Ryu receives the packet,it first learns {node6,node3's mac} = node6's port 1 mapping infomation.Because there is no mapping infomation about destination host , it sends a PacketOut message to node 6 to flood packet.
*/
當swithc 7收到封包後，就像switch 6做的事情一樣，發送一個Packet_In message 給 Ryu,然後Ryu會學習到
{swtich7,node3's mac} = switch7's port 1，然後發出一個Packet_Out 給switch7去廣播該封包，
當switch 9收到封包後，相同的事情發生，Ryu會學習到{swtich9,node3's mac} = switch9's port 2，並且也發送Packet_out給node9要其廣播出去，因為node9~node10的Link斷裂了，所以node9並不會把封包給送到node 10.
當switch 8收到來自switch 7的封包時，一樣的事情也會發生，Ryu會學習到{swtic8,node3's mac} = switch8's port 1，並且也會發生Packet_Out叫node 8給廣播出去。
當switch 10收到來自switch 7的封包時，相同一樣的事情會發生，Ryu會學習到{swtic10,node3's mac} = switch10's port 2並且發送Packet_Out給switch 10去廣播。
當node 11收到該packet後會回傳一個Tcp Ack給source host node3.
當packet到達swtich 10時，就如同之前一樣，Controller會學習到{swtic10,node11's mac} = switch10's port 4
Ryu因為之前學習的結果，知道hose 3要從port2出去，因此會發送一個flow_modify (destination mac = host3,in-port=port 4,output port = port 2} 的訊息給switch 10,並且在發送一個Packet_Out要求switch10將該封包從port 2給送出去。
/*
After node 7 receives the packet.like what has occurred on node 6,it issues a PacketIn message to RYU and RYU learn {node7,node3's mac} = node7's port 1.
NOX also sends a PakcetOut message to instruct node 7 to flood packet.
On the other hand.after node 7 receives the packet from node 6, the same scenario happen,it issues a PacketIn message to RYU .RYU learns {node9,node3'mac} = node9's port2 and sends a PacketOut message to node9 asking it flood packet.
However,because the link between node 9 and node 10 are down,node 9 does not flood packet to node 10.
After node 10 receive the packet from node 7,the same scenario happen and RYU learns {node10,node3's mac} = node10's port2 and sends a PacketOut to instruct node 10 to flood packet.
Finally,when destination host (node 11) receives the packet, it sends a TCP ACK packet to source host (node 3).When the packet arrives node 10,beacuse there is no flow entry that the packet can match, node 10 issues a PacketIn to RYU and RYU learns {node10,node11's mac} = node10's port 2.
Now with the mapping infomation learned before,RYU issues a FlowModify message to node 10  instructing it to add a new flow entry of (destination mac =host3's mac ,ingress-port =port 4,output port =port 2) and issues a PacketOut message to node 10 asking it to output the packet to port 2.              
*/
當switch 
7收到該封包，如同先前的情境一樣，會先發送Packet_In到Controller,然後Ryu會先學習到{swtic7,node11's mac} = switch7's port 3,Ryu會發送一個flow_modify (destinatiom mac = host3,in-port=port 3,output port = port 給switch 7並且在發送一個Packet_Out的訊息要switch 7將該封包從port 1送到swtich 3。
當swtich 6收到該封包後，上述的行為都會再做一次， 最後TCP ACK 就會到達node 3完成了TCP DATA-ACK round trip.
當TCP-ACK到達node3的時候，the route from host 11 to host 3  has completed, but from host 3 to host 11 not yet.當第二個TCP Data從送到switch 6時，就像之前一樣，發送一個Packet_In messasge 給Ryu,然後發送一個flow_modify( detinaion mac= host11,in-port =1,output = port 2},並且在發送一個packetOut給switch要其將封包從port2送往switch 7
當swtich 7收到後，按照之前的流程，封包會送到switch8,最後會轉送到host 11
當第二個TCP ACK到達host11後，這時候 the route from host 3 to host 11 has complated。
做到這個地步後，不論是正向或是反向傳送所需要的flow entry都正確的寫入node 6,7,10的flow table.
到目前為止，在兩端之間傳送所需要的flow entry都正確寫入到....
/*
After node 7 receives the packet, the same scenario happen , RYU learns {node7,node11's mac} = node7's port3 mapping infomation . Ryu also issues a FlowModify message to node 7 instructing it to add a new flow entry of (destination mac = host3's mac,ingress-port = port3,output-port =port 1} and issues a PacketOut message to node 10 asking to output the packet to node 3 via port 1.
After node 7 receives the packet, the same scenario happen and sends a packet to node 3 via port 1.
Ｆinally, the TCP ACP arrives node 3 to
When TCP ACK enters node 3,the route form destination host  to source host  has complete, but the route from source host to destination host has not complete yet and node 3 will send second TCP DATA packet to destination host.After packet enters node 6,the same scenario happen, node 6 issue a PacketIn message to RYU and RYU issues a FlowModify message and PacketOut message to node 6 . Finally, after the packet enter the node 11, the route from source host to destination host has complete.
So far,the flow entry that the rotue between host 3 and host 11 needs all correctly add to node6 , node 7 and node 10.
*/
-------------
|nox的運作原理。
-------------
///

///
NOX's STP use LLDP  (Link Layer Discovery Protocol) to discover the topology of an OpenFlow network and build a spanning tree over 
When openflow switch  estiblishes a TCP connection to NOX,NOX immediately sends a FlowModify message to  it  and  add an flow entry into its flow table.This flow entry will match received LLDP packet and output it to controller.
To discover whole network topology,NOX send LLDP packet to all switch ports perodically.
if there are N switch ports in network,NOX send a LLDP every 5/N seconds.
For each port of a switch,NOX will send a PackOut message to the switch and ask it to send LLDP packet carried in PacketOut message out of specified port every 5 seconds (the LLDP transmission interval).Because Nox has taught switch how to process LLDP packet before,when a swtich receives a LLDP packet from other switches, it will send the received LLDP packet to NOX. With these received LLDP packet from switches,NOX knows the complete network topology and build a spanning tree over it.For each link in the topology,
NOX sends a PortModify message to the switch which locate at the two endpoint of each link in networkFor each link in topology,NOX sends a PortModify to switch which locate at two endpoing of the link.
This message set the flooding status of the port connected the link to FLOOD/NO_FLOOD according to the link is include/exclude in spanning tree. NOX sets up a 10-second （which is two times of LLDP transmission interval) timer to monitor a link's connectivity when it has been detected. When link's timer expires , NOX thinks this that this link is currently down and rebuild the new spanning tree.Then it send a PortModify message to swtiches to chagne the flooding status of the affected ports.

/////
要修改，因為ＮＯＸ的ＬＢＰ有點差別
ＮＯＸ的ＬＢＰ跟ＲＹＵ的ＬＢＰ非常類似，唯一不同的是當ＮＯＸ送packout給switch要他flood的時候
因為nox會使用spanning tree，所以不再spanning tree上面的port就會被disable
因此當switch要flood該packet時，被設定為ＮＯ＿ＦＬＯＯＤ的port就不會把該封包給flood出去。
In the following,we will focus on how STP works because NOX's LBP works as same as Ryu.
/////
NOX use LBP to fulfill packet forwarding.
NOX's LBP and RYU's LBP are similar.
The only difference is that NOX use spanning tree to avoid broadcast storm.
We use figure(1) to explain how it works on this network.
NOX use STP to build a spanning tree as show in Figure 1( 9the spanning tree is composed of the links in red color and all links connecting a host to a switch).
Suppose the source node 3 send a TCP DATA packet to destination node 11.
When node 10 received flood packet from node 7,it issue a PacketIn message to NOX, NOX issue a Packout message to node 10 and instruct node 10 to flood the packet.
However,because the status of port 1 of node 10  has set to NO_FLOOD due to those ports are not include in spanning tree, node 10 does not flood the packet on the port 1 .
.
 


when NOX send packout to switch and instruct it to flood packet to its neighbor switch it



  
  
  
  
 //////////// 
PERFORMANCE EVALUATION
在這個部分，首先我們會先在case1去觀察ryu再有Loop的網路環境中會有何種現象。
接者在Case2中我們會致力於研究how quickly a tcp flow can chagne its path to new path when topology chagned by using Ryu and Nox in a loopless network topology.
我們會在模擬過程中故意讓node6~7的link在60~120的時候斷掉，node9~10的在0~60秒,120~150斷掉 (in case2)

In this section, we have two simulation cases to studied.
In case 1,We observed the phenomenon of RYU which only using LBP components in a network topolgoy with loop .
In case 2,We studied how quickly a tcp flow can change its path to new path when toplogy has changed by using RYU and NOX in a network topology without loop.

case1: 
Our simulation result show there are some critical problems using RYU as OpenFlow controller in a topology with loop.Broadcast storm and incorrect flow entry are add into OpenFlow switches.
We use the Figure 1 to explain why  those problems occurs.
Before the source host send TCP data to destination host, it must broadcast the ARP requestr to learn the destination host's MAC address.After node 6 receives this Packet,it issues a PacketIn Message to RYU. RYU learns the {node6,node3's MAC} = node6's port1 and RYU does not know any infomation about destination MAC address 0xffffffffffff and sends a PacketOut message to node 6 asking it flood the packet.After Node 7 and node 9 receive the packet,the same scenario happen and both nodes 7 and 9 flood the packet.
Node 10 will receives two packets, one from node 7 ,another from node 9.We assume the packet receiving order is node 9 than node 7, Node 10 send two PacketIn messages to RYU and receives two PcaketOut message to flood those packet.
After node 9 receives the packet,the same scenario happen, RYU learns {node9,node3's MAC} = node9's port 2 and override the infomation learned before.
After node 7 receives the packet,the same scenario happen, RYU learns {node7,node3's MAC} = node7's port 3 and override the infomation learned before.
After node 11 receives the packet, it response a ARP reply to node 3.
After node 10 receives the packet,the same scenario happen,node 10 issues a PacketIn message to RYU and RYU learns {node10,node11's MAC} = node10's port.RYU sends a FlowModify message to node 10 instructing it to add a new flow entry of (destination MAC = host3's MAC,ingress-port = port 4,output port = por 1 ) according to the infomation learned before.RYU also sends a PacketOut message to node 10 aksing it to output packet to port 1.
After node 7 receives the packet, the same scenario happen,RYU sends a FlowModify message to node 7 instructing it to add a new flow entry of (destination MAC = host3's MAC,ingeree-port = port 3,output  pot= port 3) and sends a PacketOut message to node 7 asking it  to output packet to port 3.
Because the packet ingress-port and output port are same, the OpenFlow switch will drop this arp-reply packet.
Because the openflow idle/hard timeout are set to infinit,the flow entry never expires.
Those incorrect flow entries are added into OpenFlow switch cause any packet sendto node 3 from node node 11 will be dropped at node 7.
On the other hand,because RYU never learns the infomation of MAC address 0xffffffffffff,it will ask OpenFlow swtich to flood the ARP-request.
For each ARP-request, it will be copied and flood many times.
Finally,the ARP-reques will occupy the bandwidth and cause broadcast storm.



/
最後 arp-request會在網路中不停廣播& COPY，會浪費很多頻寬，產生風暴。
/
////
  廣播風暴，簡單拓樸，所以COPY 一份， 如果LOOP更多，FLOOD會COPY更多份的資料使得網路完全被ARP給塞爆
  然後因為LOOP的關係，會使得ROUTE完全建立不起來，TCP 連基本的連線都無法成功。
////
	我們的模擬結果顯示Ryu在一個有Loop的網路環境是沒有辦法Work的，並且會有下列問題
  Broadcast storm.
  錯誤的flow entry在swtich 的flow table中導致tcp 連線沒有一個正確的route可以送資料。
  我們使用圖一來解釋這些現象的產生。
  當host3第一次要將封包送到node11時必須要先透過ARP去詢問node11 ip對應的mac address,因此當arp request到達node 6的時候，會因為flow table中沒有找到符合的flow entry,因此產生table miss event並發送Packet_In message到Ryu,
  Ryu因為採用了LBP的緣故，這時候會學習到{swtich6,node3's mac} = switch6's port 1 並且對於destination mac (0xffffffff} 沒有任何資訊，所以會發送一個Packet_Out給switch 6 要他廣播出去。
   當switch 7收到來該封包後，如同之前的行為，也會產生Packet_In給Ryu,Ryu會學習到{swtich7,node3's mac} = switch7's port 1 }並且發送一個Packet_Out給switch 7要其廣播。
   當swtich 9收到該封包後後，如同之前的行為，也會產生Packet_In給Ryu,Ryu會學習到{swtich9,node3's mac} = switch9's port 2 }並且發送一個Packet_Out給switch 7要其廣播。
   switch 10會收到兩份封包，分別來自swtich 7,9 這邊我們假設其收到的順序是node7,node9，按照之前的情境，switch 10 就會產生兩次的Packet_In給ryu,對於第一次的Packet_In,Ryu會學習到{swtich10,node3's mac} = switch10's port 2 ,第二的Packet_In,Ryu會重新到{swtich10,node3's mac} = switch10's port 1 ,並且產生兩次的Packet_Out給switch10要其廣播，
  當swtich 7收到來自switch 10廣播的封包時，根據先前的情況，switch 7會發送Packet_In給Controller，Ryu會學習到
 {swtich7,node3's mac} = switch7's port 3 } 並且送一個Packet_Out的封包給switch 7要他廣播出去。
  當swtich 9收到來自switch 10廣播的封包時，根據先前的情況，switch 9會發送Packet_In給Controller，Ryu會學習到
 {swtich9,node3's mac} = switch9's port 1 } 並且送一個Packet_Out的封包給switch 9要他廣播出去。
 當node 3收到封包後，由於該封包是個arp-request,node 3便會回一個arp-reply給node 3.
 當此封包到達switch 10時，像之前的情況一下，swtich 10發送一個Packet_In message給Ryu,Ryu會學習到
 {swtic10,node11's mac} = switch10's port 4，因為先前學習的結果，controller知道node3要怎麼走，所以會送一個
 flow_modify{desinaion mac ,in-gress port,output port} = {node3's mac,port 4,port 1}，並且會再送一個Packet_Out給switch 10要其將封包由port 1送給switch 7.
 當switch 7收到該封包時，就如同先前的情況一下，swtich 7發送一個Packet_In message給Ryu,Ryu會學習到
 {swtic7,node11's mac} = switch7's port 3，因為先前學習的結果，controller知道node3要怎麼走，所以會送一個
 flow_modify{desinaion mac ,in-gress port,output port} = {node3's mac,port 3,port 3}，並且會再送一個Packet_Out給switch 7要其將封包由port 3送出。
 但是在openflow switch中，因為該封包的in-gree port 跟 Packet_Out 的output port相等，因此這個arp-reply封包就會被swtich 7給丟棄了。

另一方面，一開始的ARP 封包會因為DESTINATIO斯學不到，所以繼續廣播。

簡單總結一下，當有封包從node 11送往node3的時候，switch 10會把該封包送給switch 7,然後swtich 7會因為該近來封包的in-gress port跟flow-entry的output port相同便將該封包丟棄，因此node 11永遠都沒有辦法把封包送到node11。
造成錯誤的flow-entry被寫入在switch中的原因是因為Ryu只有使用LBP去學習並且轉送封包，因此不停的廣播會使得switch對於同樣的source mac不斷學習，每次學習的資訊都不盡相同，以switch 7來說，最初的Packet_In時Ryu認為node 3在switch 7的port 1,接下來收到switch 10廣播的封包，又重新學習到node 3在switch 7的port 3.
 
  
//not yet
RYU only use LBP to fulfuill path finding and packet forwarding.We had explaind what will happen when use RYU as controller in a toplogy with loop.Therefore,we purposely shutdown the link to form a topology without loop.

Our results show that the TCP flow never changes its path to new path during the link downtime and becomes active agin over the orginal path after the link downtime both ARP is enabled or disabled.


We use timeline to display the significant event of TCP flow and ARP flow when ARP is enabled on hosts in Figure 2(a).Because we want to observe the related event of changing to new path,our X-coordinate only focus from 40'th sec to 80'th sec.

The events A, B, C, D, E, H represent the timestamp when the TCP flow tried to resend a packet due to the packet lost on the broken link,and the events F and G represent the timestamp when the source host broadcast the ARP request to learn the ARP record again.The ARP request transmission occurs beachuse on the source host the ARP record for the destination host had expired during the long TCP retransmission interval.
We found that there are no TCP flow,only ARP requesst  around the timestamp of event F and G, the reasons we will explain below.

The timestamp of event A occurs at 40.4'th sec and the interval between two successive retransmission events starting from event A are 0.65, 1.41, 2.912, 5.84, 11.79 and 23.884 seconds,respectively.These exponentially-growing intervals are caused by the TCP congestion control algorithm on the source hosts.The G event represents the successful retransmission of the lost packet over the original path whean the link between nods 6 and 7 becomes active up again at 80'th sec.
//
In the following , we will explain (1) why TCP flow cannot changes to new path during the link downtime and (2) there are only ARP request at timestampe of evnets F and G.
The reason why the TCP retransmission attempts at events A,B,C,D, and E fail are the same.
The reason why there are only ARP request at events F and G are the same.
Before the link be shutdown at 40'th sec,RYU use its LBP to find a routing path from source host to destination host which traverse the node 6,7, and 10.
RYU also sends the FlowModify message and PacketOut message to switchs and the idle timeout value and the hard timeout value associated with flow entry are set to 0.
An idle timeout value indicates when the entry should be removed
due to no packet of this flow enters the switch to match this flow ,as well as a hard timeout value that indicates when the entry should be removed after it added to flow table.
If both idle_timeout and hard_timeout are zero, the flow entry is
considered permanent and will never expired.
At the tmestamp of event A.Whan a TCP data packet enters the node 6 after the link between nodes 6 and 7 be shutdwon at 40'th sec,because there is a flow entry in the flow table thc the TCP data packet  can match it and the flow entry will forward the packet over the port 1 to a broken link.
Therefore,the destination host cannot receive any packet sent from source host.
At the timestamp of event F,the source host broadcast ARP request before it retransmits the pakcet lost on the broken link.
When the ARP request enters the node 6,beacuse there are no flow entry which matchd for broadcast packet and its sends a PacketIn message to RYU.RYU sends a PacketOut message to node 6 asking it to flood the packet.Finally,the ARP request  will enters the destination node and it will reply a unicast ARP reply to node 3.When the ARP reply enters the node 11,it will forward the packet out of port 2 to node 7 according to the flow entry it learns before.
When the ARP reply enters the node 7, it will forward the packet out of port 1 to the broken link.
Therefore,the source cannot receive the ARP replay and will not resend the TCP data.
At the timestamp of evet G,the link downtime has passed,the source host can receives the ARP reply and the TCP flow becomes actives again over the original path.

When ARP is disabled on hosts, as shown in Figure 3 (b),the TCP flow still cannot changes to the new path during the link downtime.The reasone and the phenomenon are as same as when ARP is enabled on hosts,except for the events F and G.
In the following , we will explain the difference between them.
Because the ARP is disabled on hosts,the source host will use the pre-build ARP record instead of broadcasting ARP request,the source will resend the TCP packet lost on the broken link at the timestamp of events F and G.

We found that the TCP flow cannot changes its path to new path and becomes active again after the link downtime is caused by the improper value of flow idle timout and flow hard timeout .
To fix this design flaws,we suggest to modify RYU  so that the flow entry will be expired periodically.



圖2(b)是一個 timeline of the important event of the TCP flow when ARP disable.
ABCDEFGH(A=60.25)
A~H代表的分別是tcp重送data的時間，
這些evnet間隔分別是0.577，1.138，2.271，4.544，9.04，18.174，36.352
A~G之間TCP會失敗的原因如同 arp is enabled.
唯一不同的是因為arp 是build in的方式，所以source host不會發送arp-request.因此在FG這兩個時間點時source host都會嘗試將TCP DATA重送 而非 ARP-request .
在H時段時，TCP FLOW 將會繼續使用舊的路徑去傳送。


根據圖2(a,b)的實驗我們可以瞭解到Ryu由於timeout的問題所以沒有辦法找尋到新的路徑，如果要使得Ryu在link斷掉後可以找到新路徑，就必須要設定idle timoue & hard timout 讓在swithc 中的flow entry expire 。



NOX
圖1顯示了原本的spanning tree.
40秒後的STP在圖片2
in the following,我們想要展示 (1) ARP 開啟 ， 新路徑會在啥時候找到， 然後新路徑是啥 之後不會回到就路徑(2) ARP關閉 後 並不會找到新路徑，之後又繼續送。我們發現會造成這樣的結果與FLOW ENTRY的TIMER 值相關。是NOX載 LBP STP設計的一些小缺失。

圖X 是時間軸，顯示了

On the tested network shown in Figure 1,we show the NOX's spanning tree before the link failure.
We purposely shut down the link between nodes 9 and 10 at 0'th sec.After the link between nodes 6 and 7 breaks at 40'th sec and the link between nodes 9 and 10 join at 40'th sec.NOX rebuilds the spanning tree which is shownn in Figure 2.
we purposely shut down the link between nodes 9  and 10 at 0'th sec.Beforc the link between nodes 6 and 7 breaks at 40'th sec and the link between nodes 9 and 10 join the network again at 40'th sec,NOX builds the spanning tree, which is shown in Figure 2.Therefore , the TCP flow from the source host to detination host traverse nodes 3,6,7,10,and 11.
In the following,we show that (1) when ARP is enabled,the TCP flow will change its path to new path traversing nodes 3,6,9,10, and 11 at 58'th sec. However,the TCP flow never change back to old path after the link between nodes 6 and 7 becomes up again; and (2) when ARP is disabled.the TCP flow never change its path to the new path when the link between nodes 6 and 7 shutdown at 40'th to 80'th and becomes active again over the old path at 97'th sec.These results are caused by the flow idle/hard timers used in OpenFlow switches.NOX's LBP and STP implementations and their interactions with ARP.

We use timeline to display the significant event of TCP flow when ARP is enabled on hosts in Figure 3 (a).Because we want to observe the related event of changing to new path,our X-coordinate only focus from 40'th sec to 80'th sec.
Since the link between nodes 6 and 7 has been shutdown at 40'th sec,as discussed perviously,because  NOX's STP detect the link's status every 10 seconds.We expected to see the new spanning tree would be build around 50+'th sec and TCP flow changes to new path after the new spanning tree is build.
However,our simulation results show the TCP flow actually changes its path to new path around 59'th sec.
//
ＡＢＣＤＥＦ這些事件代表者ＴＣＰ嘗試要重送資料 （那些資前被丟掉的資料）
ＡＢＣＤＥＦ的時間分別是ＸＸ，彼此之間的差距成一個指數的上升，這是因為ＴＣＰ的congestion control ....
F EVENT代表的是一個在新路徑上成功地重送，在這之後，ＴＣＰ連線都會使用新的路徑來傳送資料。
Ｘ事件是被Ｆ給引起的，是一個ＡＲＰ的發問，因為在ＴＣＰ蟲送機制中，ＡＲＰ的記錄ＥＸＰＩＲＥ掉了，所以要重新發送ＡＲＰ去學習。 （三渺）
//
The events A, B, C, D, E, and F represent the timestamp when the TCP flow tried to resend a packet due to the packet lost on the broken link.The timestamp of event A occurs at 40.45'th sec and the interval between two successive retransmission events starting from event A are 0.55, 1.21, 2.40, 4.87, and 10.3 seconds,respectively.These exponentially-growing intervals are caused by the TCP congestion control algorithm on the source hosts.The F event represents the successful retransmission of the lost packet over the new path.During the timestamp of event F to 80'th sec, the TCP flow will use the new path to send data. The X event represents the ARP request which is triggered by the TCP flow retransmissing the lost packet at the F timestamp.Because the ARP record will expire during the long TCP retransmission interval on source host (the expiration time of an ARP record is 3 seconds only), source host broadcast ARP request to the network to learn the ARP record again.

In the following, we explain why the time the TCP flow changes to new path unexpectedly occurs at 50+'th sec when ARP is enabled.The reaswon why  the retransmission attempts at events A,B,C,D and E fail are same.
When NOX add a flow entry into switch's flow table, the idle timeout value associated whti this entry are set to 5 seconds.This means that a flow entry will not expire unless no packet of this flow enters the switch to match this flow for 5 seconds.Accroding to EstiNet and NOX log, we found that NOX formed the new spanning tree at 51'th sec,which is after the timestamp of event E. Therefor, all of the  packet are forwarded over the broken link and got lost before the new spanning tree is formed.
When NOX rebuild the spannig tree, it will send PortModify message to swtich instructing it to modify the status of each port to FLOOD/NO_FLOOD accroding to spanning tree's configuration.
As for the retransmission at event F, it succeeds and the reason is explained below.
Because the interval between timstamp of event E and timestamp of event F is bigger than 5 seconds.
each flow entry of all switches are expired.
Because the ARP record is expired,the source host broadcast ARP request at timestamp of event X to learn the mapping inforamtion.After ARP request enters the node 6,there are no flow entry in its flow table and it sends a PacketIn message to NOX asking for forwarding instructions.NOX sends a PacketOut message to node 6 asking it flood the ARP request out of all its FLOOD port.As a results.the ARP request travese node 6,9, and 10 to reach the destination host and destination host send back the unicastARP reply back to the source host and NOX'LBP forward this packet to node 3.
The ARP request and reply not only let NOX learn the lastest forwarding infomation but also 
install new  ARP flow entries into switches.
Later,when the resent TCP packet enters to node 6,because there is no entry for this TCP flow in its flow table,node 6 sends a PacketIn message to NOX asking for instruction.
NOX sends a FlowModify message and PcaketOut message to node 6 asking it to add a new flow entry for this TCP flow and forwarding the TCP packet out of port 3.
After that.this TCP DATA and its TCP ACK packet follow the scenario described in Section XXX to (1) update NOX of lastest  forawrding infomation  and (2) install correct flow entries for this TCP flow in all switches.Finally,the TCP flow becomes active to use the new path around 58'th sec.

//(IDLE TIME  5 sec)
接下來，我們解釋為什麼 ＴＣＰＦＬＯＷ改變ＰＡＴＨ的時間不如我們預期的在50+左右 當ＡＲＰ有啓動的時候
ＡＢＣＤＥ會延後的理由都一樣。
NOX插入的FLOW ENTRY 的IDLE TIMEOUT 是5秒，代表距離上次送過來差五秒以上，就會消失。
我們根據模擬器跟ＮＯＸ的ＬＯＧ去觀察，我們發現到ＮＯＸ在50'th左右才把新的ＳＴＰ給重新建立了一次，所以在這個時間點之前的事件Ａ～Ｅ全部的封包都會被送到一個斷掉的ＬＩＮＫ而ＬＯＳＴ調。
當ＮＯＸ把ＳＴＰ重新建立完畢後，所有的ＰＯＲＴ都會根據ＳＴＰ資訊而被設定成ＦＬＯＯＤ根ＮＯＮ＿ＦＬＯＯＤ
關於Ｆ這個時段的重送，它是成功地，我們在下面解釋理由
由於E跟F之間的差距>5秒，所以這時候OpenFlow swtich鐘的flow entry都已經expire了
在Ｆ送出ＴＣＰＤＡＴＡ前，因為ＡＲＰ的記錄都消失了，所以會產生一個ＡＲＰ的ＲＥＱＵＥＳＴ（這是Ｘ時段）
在長時間的ＴＣＰ蟲送機制中，所有被寫入到ＳＷＩＴＣＨ的ＦＬＯＷ ＥＮＴＲＹ都會ＥＸＰＩＲＥ掉，所以當有ＡＲＰ
ＲＥＱＵＥＳＴ送到ＳＷＴＩＣＨ的手上的時候，便會產生pakcet_In 去問ＮＯＸ該怎麼做，ＮＯＸ會回傳一個ＰＡＣＫＥＴＯＵＴ叫他從所有不包含ＮＯＮ＿ＦＬＯＯＤ的ＰＯＲＴ廣播出去，最後這個封包就會經過 這三個swtich 6,9,10最後到達了node11.
最後node11回送了一個unicast的arp reply給node 3. 接下來透過ＬＢＰ的就可以把這個reply順利地送回去。
ＡＲＰ的ＲＥＱＵＥＳＴ根ＲＥＰＬＹ會使得ＮＯＸ去學習到目前網路中最新的情形，之後當ＴＣＰ蟲送資料 node 11.
當封包到達node 6之後，因為沒有ＥＮＴＲＹ可以ＭＡＴＣＨ，這時候會發生ＰＡＣＫＥＴＩＮ給ＮＯＸ，然後ＬＢＰ會根據ＡＲＰ ＲＥＰＬＡＹ所學到的ＩＮＦＯＲＭＡＴＩＯＮ送出一個ＦＬＯＷＭＯＤＩＦＹ去更新ＥＮＴＲＹ並且送出一個ＰＡＣＫＥＴＯＵＴ要他漿封包往從port X送出。 這個ＴＣＰ的ＤＡＹＡ跟他的ＡＣＫ根據之前所描述的情竟在 ＳＥＣＴＩＯＮＸＸ
將會（1) 更新NOX中的ＦＯＲＷＡＲＤＩＮＧ ＩＮＦＯＭＡＴＩＯＮ （2)插入正確的flow entry到所有新路徑上的swtich
當所有正確的心ＦＬＯＷ 都插入到ＳＷＩＴＣＨ之後，ＴＣＰＦＬＯＷ就可以順利使用新路徑來傳送封包在58秒左右。

In constrast to the fact that the TCP flow can change to new path when ARP is enabled, when ARP is disabled the TCP flow never changes to the new path but instead becomes acvite again over the original path at 81'th sec.In the following,
We use figure 3(b) to explain the reasons.
Because ARP is disabled on host and  host will use the pre-build ARP record instead of broadcasting ARP request,each events of figure 3 (b) are represends the timestamp when TCP flow resend a packet.
When the TCP retransmission attempt at event F fails,because the TCP congestion control algorithm,this faiure doubles the TCP retransmission interval from 10.3 to 20.6 seconds and causes the next retransmission at the timestamp of event F plus 20.6 seconds,which is at 81'th sec (at the G timestamp).
At the timestamp of event G, because the link between nodes 6 and 7 becomse up again at 80'th sec, the TCP flow still uses its original path to successfully transmit its packet.

對比於 當ＡＲＰ開啓時，ＴＣＰ ＦＬＯＷ可以正確的轉移位置， 當ＡＲＰ關閉的時候，ＴＣＰ ＦＬＯＷ不會切換到新路徑並且會在某秒數的時候繼續從舊的路徑傳送。
接下來我們會解釋原因。
我們以圖3(b)來解釋其原因，當ARP 關閉的時候，HOST 會使用PR-build的ARP RECORD instead of broadcast ARP-request.所以我們的EVENT全部都是TCP重送的EVENT。
當TCP 載F 這個點重送失敗後，由於tcp CONGESTION CONTROL的緣故，下一次重送的尖閣則是兩倍的10.3 就是20.6
所以下一個event g 則是在80+附近。 載event g， 由於link已經回來啦而且nox沒有找到新路徑過，所以nox 又繼續地從舊路徑傳送。

As for the reason why ths retransmission fails at timestamp of event E when ARP is disabled.We found that it is caused by a bug of NOX's STP.For each flow entry added to the flow table of a switch,the switch sets up a 5 seconds idle timer for it and will remove the flow entry if it hsa not been used more than 5 seconds.Therefore,when a resend TCP data enters node 6,because the flow entry of this TCP flow has exipred and been removed before,it sends a PacketIn message to NOX asking for instruction.
Because there are no broadcast ARP packet over the network, NOX has no change to update lastest forwarding information.NOX sends a FlowModify message and PacketOut message to node 6 with wrong forwarding information and instructs node 6 to forward  the TCP packet to the broken link.
Therefore, the packet cannot be received by destination host.  
At the timestamp of event G,the source host resends TCP pacaket again and the link has becomes up again at 80'th sec and the TCP flow can successfully transmit its packet  over its original path.
To fix this design flaws,we suggest to modify the NOX so that the (source node,ingress port) mapping infomation learned by NOX's LBP can be expired periodically.

Another significant problem we found in figure 3(a) is that the TCP flow does not changes its path from new path to its original path after the link downtime,even thought the spanning tree has been rebuild to the original one.This problem is caused by the improper value of idle timout and hard timeout and those are set to 5 seconds and infinite respectively.
As long as the TCP flow sends packet over the new path,each flow entry of switchs will never expire.
Since every incoming TCP packet will match these flow entries and will not trigger table miss event, these switches will not sends PacketIn message to NOX.
Thereofe,NOX has no chance to install new entries into the flow table of those swtichesto change the path of TCP flow back to its original one.

As for the reason 為什麼ARP關掉的時候，載P重送卻會失敗， 我們發現這是因為NOX的機制不夠完善所導致的
每個flow entry被插入到SWITCH的時候，都會有一個五秒的TIMER，只要這個FLOW ENTRY五秒內都沒有被使用到，這個FLOW ENTRY就會被刪除，所以在TCP 在時間點P要重送的時後之前，SWTICH內的FLOW ENTRY都會自動被刪除。所以當TCP DATA送到NDOE6的時候就會因為switch中找不到對應flow entry,因此產生packetIN給swtich.

由於NOX'LBP 沒有透過ARP REQUEST \ REPLY 更新資訊，所以NOX 錯誤的把FLOW ENTRY 給寫入到SWTICH 並且較SWTICH把該封包送到一個斷掉的LINK。因此封包就不會送到NOde11.
當時間點G的時候因為斷掉的LINK已經復活了，所以這時候的TCFLOW就可以透過舊有的路徑去傳送資料。為了修正這個設計上的缺陷，我們認為NOX鐘LBP的MAPPING INFORMATION 必須要週期性的FLUSH。


另一個我們發現的顯著問題在圖3(a) 就是 TCP FLOW 並不會切換到切回去原本的舊路徑即使的SPANNING TREE重建過了

這個問題產生的原因是因為NOX在發送flowModify時對應的idle timeout = 5sec,hard_timeout設定為infinint
所以當tcp flow一直使用新路竟在傳送資料的時候，整個flow entry並不會被消除，所以每次近來的封包都有flow entry 可以match,如此一來就不會發生PacketIn給NOX。因此
NOX 沒有辦法插入新的FLOW ENTRY 給這些SWITCH  使得TCP FLOW 採用原本的路徑。

//







